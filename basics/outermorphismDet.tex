%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

%
%
\chapter{Outermorphism Question}
\index{outermorphism}
\label{chap:outermorphismDet}
%\date{Sept. 2, 2008.  outermorphismDet.tex}

\section{}

\citep{doran2003gap}
has an example of a linear operator.

\begin{equation}\label{eqn:outermorphism_det:F}
F(a) = a + \alpha(a \cdot f_1) f_2.
\end{equation}

This is used to compute the determinant without putting the operator
in matrix form.

\subsection{bivector outermorphism}

Their first step is to compute the wedge of this function applied to two vectors.  Doing this myself (not omitting steps), I get:

\begin{equation}\label{eqn:outermorphismDet:21}
\begin{aligned}
F(a \wedge b)
&= F(a) \wedge F(b) \\
&= (a + \alpha(a \cdot f_1) f_2 ) \wedge (b + \alpha(b \cdot f_1) f_2 ) \\
&= a \wedge b + \alpha(a \cdot f_1) f_2 \wedge b
+ \alpha (b \cdot f_1) a \wedge f_2
+ \alpha^2 (a \cdot f_1) (b \cdot f_1) \mathLabelBox{f_2 \wedge f_2}{\(=0\)} \\
&= a \wedge b
+ \alpha \left( (b \cdot f_1) a - (a \cdot f_1) b \right) \wedge f_2
\\
&= a \wedge b
+ \alpha \left( (a \wedge b ) \cdot f_1 \right) \wedge f_2
\end{aligned}
\end{equation}

This has a very similar form to the original function \(F\).  In particular
one can write

\begin{equation}\label{eqn:outermorphismDet:41}
\begin{aligned}
F(a)
&= a + \alpha(a \cdot f_1) f_2 \\
&= a + \gpgradeone{\alpha(a \cdot f_1) f_2} \\
&= a + \gpgrade{\alpha(a \cdot f_1) f_2}{0+1} \\
&= a + \alpha(a \cdot f_1) \wedge f_2 \\
\end{aligned}
\end{equation}

Here the fundamental definition of the wedge product as the
highest grade part of a product of blades has been used to show that the new
bivector function defined via outermorphism has the same form as the original, once we put the original in the new form that applies to bivector and vector:

\begin{equation}
F(A) = A + \alpha(A \cdot f_1) \wedge f_2
\end{equation}

\subsection{Induction}

Now, proceeding inductively, assuming that this is true for some grade \(k\) blade A, one can calculate \(F(A) \wedge F(b)\) for a vector \(b\):

\begin{equation}\label{eqn:outermorphismDet:61}
\begin{aligned}
&F(A) \wedge F(b) \\
&= (A + \alpha(A \cdot f_1) \wedge f_2) \wedge (b + \alpha(b \cdot f_1) f_2 ) \\
&= A \wedge b
+ \alpha( b \cdot f_1 ) A \wedge f_2
+ \alpha (( A \cdot f_1) \wedge f_2) \wedge b
+ \alpha^2 (b \cdot f_1) ((A \cdot f_1) \wedge f_2) \wedge f_2 \\
&= A \wedge b + \alpha \left( ( b \cdot f_1 ) A - ( A \cdot f_1) \wedge b \right) \wedge f_2 \\
&= A \wedge b + \alpha \gpgrade{ ( b \cdot f_1 ) A - ( A \cdot f_1) b}{k} \wedge f_2 \\
\end{aligned}
\end{equation}

Now, similar to the bivector case, this inner quantity can be reduced, but it is messier to do so:

\begin{equation}\label{eqn:outermorphismDet:81}
\begin{aligned}
\gpgrade{ ( b \cdot f_1 ) A - ( A \cdot f_1) b}{k}
&= \inv{2} \gpgrade{ b f_1 A - A f_1 b + f_1 (b A + (-1)^{k} A b) }{k} \\
\end{aligned}
\end{equation}
\begin{equation} \label{eqn:outermorphism_det:r1}
\implies
\gpgrade{ ( b \cdot f_1 ) A - ( A \cdot f_1) b}{k} = \inv{2} \gpgrade{ b f_1 A - A f_1 b}{k} + \gpgrade{ f_1 (b \wedge A) }{k}
\end{equation}

Consider first the right hand expression:
\begin{equation}\label{eqn:outermorphismDet:101}
\begin{aligned}
\gpgrade{ f_1 (b \wedge A) }{k}
&= f_1 \cdot (b \wedge A) \\
&= (-1)^{k} f_1 \cdot (A \wedge b) \\
&= (-1)^{k} (-1)^k (A \wedge b) \cdot f_1 \\
&= (A \wedge b) \cdot f_1 \\
\end{aligned}
\end{equation}

The right hand expression in \eqnref{eqn:outermorphism_det:r1} can be shown to equal zero.  That is messier still and the calculation can be found
at the end.

Using that equals zero result we now have:
\begin{equation}\label{eqn:outermorphismDet:121}
\begin{aligned}
F(A) \wedge F(b)
&= A \wedge b + \alpha ((A \wedge b) \cdot f_1) \wedge f_2 \\
\end{aligned}
\end{equation}

This completes the induction.

\subsection{Can the induction be avoided?}

Now, GAFP did not do this induction, nor even claim it was required.  The statement is "It follows that", after only calculating the bivector
case.  Is there a reason that they would be able to make such a statement without proof that is obvious to them perhaps but not to me?

It has been pointed out that this question is answered, ``yes, the induction can be avoided'', in \citep{aMacdonaldLAGC} page 148.

%I am guessing this would be related to the matrix concept of rank in
%some way too, but it is not clear to me exactly how.

\section{Appendix. Messy reduction for induction}

Q: Is there an easier way to do this?

Here we want to show that

\begin{equation*}
\inv{2} \gpgrade{ b f_1 A - A f_1 b}{k} = 0
\end{equation*}

Expanding the innards of this expression to group \(A\) and \(b\) parts together:

\begin{equation}\label{eqn:outermorphismDet:141}
\begin{aligned}
b f_1 A - A f_1 b
&= (f_1 b - 2 b \wedge f_1 ) A - A (b f_1 - 2 f_1 \wedge b) \\
&=
f_1 b A - A b f_1
- 2 (b \wedge f_1) A + 2 A (f_1 \wedge b) \\
&=
f_1 (b \cdot A + b \wedge A) - (A \cdot b + A \wedge b) f_1 \\
&- 2 \left( (b \wedge f_1) \cdot A + \gpgrade{(b \wedge f_1) A}{k} + (b \wedge f_1) \wedge A \right) \\
&+ 2 \left( A \cdot (f_1 \wedge b) + \gpgrade{A (f_1 \wedge b)}{k} + A \wedge (f_1 \wedge b) \right)
\end{aligned}
\end{equation}

the grade \(k-2\), and grade \(k+2\) terms of the bivector product
cancel (we are also only interested in the grade-\(k\) parts so can discard them).  This leaves:
\begin{equation*}
f_1 \wedge (b \cdot A) - (A \cdot b) \wedge f_1
+ f_1 \cdot (b \wedge A) - (A \wedge b) \cdot f_1
- 2 \gpgrade{(b \wedge f_1) A}{k}
+ 2 \gpgrade{A (f_1 \wedge b)}{k}
\end{equation*}

The bivector, blade product part of this is the antisymmetric part of that product so those two last terms can be expressed with the
commutator relationship for a bivector with blade: \(\gpgrade{B_2 A}{k} = \inv{2}(B_2 A - A B_2)\):

\begin{equation}\label{eqn:outermorphismDet:161}
\begin{aligned}
2 \gpgrade{A (f_1 \wedge b)}{k}
- 2 \gpgrade{(b \wedge f_1) A}{k}
&= A (f_1 \wedge b) - (f_1 \wedge b) A - (b \wedge f_1) A + A (b \wedge f_1) \\
&= A (f_1 \wedge b) - (f_1 \wedge b) A + (f_1 \wedge b) A - A (f_1 \wedge b) \\
&= 0
\end{aligned}
\end{equation}

So, we now have to show that we have zero for the remainder:
\begin{equation}\label{eqn:outermorphismDet:181}
\begin{aligned}
2 \gpgrade{ b f_1 A - A f_1 b}{k}
&= f_1 \wedge (b \cdot A) - (A \cdot b) \wedge f_1 \\
&\quad + f_1 \cdot (b \wedge A) - (A \wedge b) \cdot f_1 \\
&= (-1)^{k-1}f_1 \wedge (A \cdot b) - (-1)^{k-1}f_1 \wedge (A \cdot b) \\
&\quad + (-1)^{k}f_1 \cdot (A \wedge b) - (-1)^{k} f_1 \cdot (A \wedge b) \\
&= 0
\end{aligned}
\end{equation}

\section{New observation}

Looking again, I think I see one thing that I missed.  The text said they were
constructing the action on a general multivector.  So, perhaps they meant
\(b\) to be a blade.  This is a typesetting subtlety if that is the case.  Let us
assume that is what they meant, and that \(b\) is a grade \(k\) blade.  This
makes the coefficient of the scalar \(\alpha\) in equation 4.147 :

\begin{equation}\label{eqn:outermorphismDet:201}
\begin{aligned}
a \cdot f_1 f_2 \wedge b + b \cdot f_1 a \wedge f_2
&= \left( (b \cdot f_1) a + (-1)^{k} (a \cdot f_1) b \right) \wedge f_2 \\
\end{aligned}
\end{equation}

whereas they have:
\begin{equation*}
\left( (b \cdot f_1) a - (a \cdot f_1) b \right) \wedge f_2
\end{equation*}

So, no, I think they must have intended \(b\) to be a vector, not an
arbitrary grade blade.

Now, indirectly, it has been
proven here that for a vectors \(x\), \(y\), and a grade-\(k\) blade \(B\):

\begin{equation}\label{eqn:outermorphism_det:distrib}
(A \wedge x) \cdot y = A ( x \cdot y ) - ( A \cdot y ) \wedge x
\end{equation}

Or,
\begin{equation}
(A \wedge x) \cdot y = ( y \cdot x ) A + (-1)^{k}( y \cdot A ) \wedge x
\end{equation}

(changed variable names to disassociate this from the specifics of this
particular example), which is a generalization of the wedge product with
dot product distribution identity for vectors:

\begin{equation}
(a \wedge b) \cdot c = a ( b \cdot c ) - ( a \cdot c ) \wedge b
\end{equation}

I believe I have seen a still more general form of \eqnref{eqn:outermorphism_det:distrib}
in a
Hestenes paper, but did not think about using it a-priori.  Regardless, it
does not really appear the the GAFP text was treating \(b\) as anything but a
vector, since there would have to be a \((-1)^k\) factor on equation 4.147 for
it to be general.
