%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

%
%
\chapter{Multivector product grade zero terms}
\label{chap:scalarCommutes}
%\date{Mar 16, 2008.  scalarCommutes.tex}

One can show that the grade zero component of a multivector product
is independent of the order of the terms:

\begin{equation}
\gpgradezero{\BA \BB} = \gpgradezero{\BB \BA}
\end{equation}

Doran/Lasenby has an elegant proof of this, but a dumber proof using an
explicit expansion by basis also works and highlights the similarities
with the standard component definition of the vector dot product.

Writing:

\begin{equation}\label{eqn:scalarCommutes:20}
\BA = \sum_i \gpgrade{\BA}{i}
\end{equation}
\begin{equation}\label{eqn:scalarCommutes:40}
\BB = \sum_i \gpgrade{\BB}{i}
\end{equation}

The product of \(\BA\) and \(\BB\) is:

\begin{equation}\label{eqn:scalarCommutes:180}
\begin{aligned}
\BA \BB
&= \sum_{ij} \gpgrade{\BA}{i} \gpgrade{\BB}{j} \\
&= \sum_{ij} \sum_{k=0}^{\min(i,j)}\gpgrade{\gpgrade{\BA}{i} \gpgrade{\BB}{j}}{2k + \abs{i-j}} \\
\end{aligned}
\end{equation}

\begin{equation}\label{eqn:scalar_commutes:product}
\BA \BB
= \sum_{ij} \sum_{k=0}^{\min(i,j)}\gpgrade{\gpgrade{\BA}{i} \gpgrade{\BB}{j}}{2k + \abs{i-j}}
\end{equation}

To get a better feel for this, consider an example

\begin{equation}\label{eqn:scalarCommutes:60}
\BA = \Be_1 + \Be_2 + \Be_{12} + \Be_{13} + \Be_{34} + \Be_{345}
\end{equation}
\begin{equation}\label{eqn:scalarCommutes:80}
\BB = \Be_2 + \Be_{21} + \Be_{23}
\end{equation}
\begin{equation}\label{eqn:scalarCommutes:100}
\BA \BB = ( \Be_1 + \Be_2 + \Be_{12} + \Be_{13} + \Be_{34} + \Be_{345})(\Be_2 + \Be_{21} + \Be_{23})
\end{equation}

Here are multivectors with grades ranging from zero to three.  This multiplication will include vector/vector, vector/bivector, vector/trivector, bivector/bivector, and bivector/trivector.  Some of these will be grade lowering, some grade preserving and some grade raising.

Only the like grade terms can potentially generate grade zero terms, so the grade zero terms of the product in \eqnref{eqn:scalar_commutes:product} are:

\begin{equation}\label{eqn:scalar_commutes:scalarproduct}
\BA \BB
= \sum_{i=j} \gpgradezero{\gpgrade{\BA}{i} \gpgrade{\BB}{j}}
\end{equation}

Using the example above we have

\begin{equation}\label{eqn:scalarCommutes:120}
\gpgradezero{\BA \BB}
= \gpgradezero{ (\Be_1 + \Be_2)\Be_2 }
+ \gpgradezero{ (\Be_{12} + \Be_{13} + \Be_{34})\Be_{21} }
\end{equation}

In general one can introduce an orthonormal basis
\(\sigma^k = \{\Bsigma_i^k\}_i\) for each of the \(\gpgrade{}{k}\) spaces.
Here orthonormal is with respect to the k-vector dot product

\begin{equation}\label{eqn:scalar_commutes:orthonormal}
\Bsigma_i^k \cdot \Bsigma_j^k = (-1)^{k(k-1)/2}\delta_{ij}
\end{equation}

then one can decompose each of the k-vectors with respect to that
basis:

\begin{equation}\label{eqn:scalarCommutes:140}
\gpgrade{\BA}{k} = \sum_i \left(\gpgrade{\BA}{k} \cdot \Bsigma_i^k\right) \inv{\Bsigma_i^k}
\end{equation}

\begin{equation}\label{eqn:scalarCommutes:160}
\gpgrade{\BB}{k} = \sum_{j} \left(\gpgrade{\BB}{k} \cdot \Bsigma_{j}^k\right) \inv{\Bsigma_{j}^k}
\end{equation}

Thus the scalar part of the product is

\begin{equation}\label{eqn:scalarCommutes:200}
\begin{aligned}
\gpgradezero{\BA \BB}
&= \sum_{k, i, j} \gpgradezero {
\left(\gpgrade{\BA}{k} \cdot \Bsigma_{i}^k\right) \inv{\Bsigma_{i}^k}
\left(\gpgrade{\BB}{k} \cdot \Bsigma_{j}^k\right) \inv{\Bsigma_{j}^k}
} \\
&= \sum_{k, i, j}
\gpgradezero { \Bsigma_{i}^k \Bsigma_{j}^k }
\left(\gpgrade{\BA}{k} \cdot \Bsigma_{i}^k\right)
\left(\gpgrade{\BB}{k} \cdot \Bsigma_{j}^k\right) \\
&= \sum_{k, i, j}
\left(-1\right)^{k\left(k-1\right)/2} \delta_{ij}
\left(\gpgrade{\BA}{k} \cdot \Bsigma_{i}^k\right)
\left(\gpgrade{\BB}{k} \cdot \Bsigma_{j}^k\right)
\end{aligned}
\end{equation}

Thus the complete scalar product can be written

\begin{equation}
\gpgradezero{\BA \BB} = \sum_{k, i}
\left(-1\right)^{k\left(k-1\right)/2}
\left(\gpgrade{\BA}{k} \cdot \Bsigma_{i}^k\right)
\left(\gpgrade{\BB}{k} \cdot \Bsigma_{i}^k\right)
\end{equation}

Note, compared to the vector dot product, the alternation in sign, which is
dependent on the grades involved.

Also note that this now trivially proves that the scalar product is commutative.

Perhaps more importantly we see how similar this generalized dot product is to the
standard component formulation of the vector dot product we are so used to.
At a glance the component-less geometric algebra formulation seems
so much different than the standard vector dot product expressed in terms of components, but
we see here that this is in fact not the case.

