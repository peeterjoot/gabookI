%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

%
%
\chapter{Cramer's rule}
\index{Cramer's rule}
\label{chap:gaWikiCramers}
%\date{October 16, 2007.  gaWikiCramers.tex}

\section{Cramer's rule, determinants, and matrix inversion can be naturally expressed in terms of the wedge product}

The use of the wedge product in the solution of linear equations can be quite useful.

This does not require any notion of geometric algebra, only an exterior product and the concept of similar elements, and a nice example of such a treatment can be found in Solution of Linear equations section of \citep{grassmanbookExteriorProduct}.

Traditionally, instead of using the wedge product, Cramer's rule is usually presented as a generic algorithm that can be used to solve linear equations of the form \(\BA \Bx = \Bb\) (or equivalently to invert a matrix).  Namely

\begin{equation}\label{eqn:gaWikiCramers:20}
\Bx = \frac{1}{|\BA|}\operatorname{adj}(\BA)
\end{equation}

This is a useful theoretic result.  For numerical problems row reduction with pivots and other methods are more stable and efficient.

When the wedge product is coupled with the Clifford product and put into a natural geometric context, the fact that the determinants are used in the expression of \({\mathbb R}^N\) parallelogram area and parallelepiped volumes (and higher dimensional generalizations of these) also comes as a nice side effect.

As is also shown below, results such as Cramer's rule also follow directly from the property of the wedge product that it selects non identical elements.  The end result is then simple enough that it could be derived easily if required instead of having to remember or look up a rule.

\subsection{Two variables example}

\begin{equation}\label{eqn:gaWikiCramers:40}
\begin{bmatrix}
\Ba & \Bb
\end{bmatrix}
\begin{bmatrix}
x \\ y
\end{bmatrix}
= \Ba x + \Bb y = \Bc
\end{equation}

Pre and post multiplying by \(\Ba\) and \(\Bb\).

\begin{equation}\label{eqn:gaWikiCramers:60}
      ( \Ba x + \Bb y ) \wedge \Bb = (\Ba \wedge \Bb) x =       \Bc \wedge \Bb
\end{equation}
\begin{equation}\label{eqn:gaWikiCramers:80}
\Ba \wedge ( \Ba x + \Bb y )       = (\Ba \wedge \Bb) y = \Ba \wedge \Bc
\end{equation}

Provided \(\Ba \wedge \Bb \neq 0\) the solution is

\begin{equation}\label{eqn:gaWikiCramers:100}
\begin{bmatrix}x \\ y\end{bmatrix}
= \frac{1}{\Ba \wedge \Bb}
\begin{bmatrix}
\Bc \wedge \Bb \\ \Ba \wedge \Bc
\end{bmatrix}
\end{equation}

For \(\Ba, \Bb \in {\mathbb R}^2\), this is Cramer's rule since the \(\Be _1 \wedge \Be _2\) factors of the wedge products

\begin{equation}\label{eqn:gaWikiCramers:120}
\Bu \wedge \Bv = \begin{vmatrix}u_1 & u_2 \\ v_1 & v_2 \end{vmatrix} \Be _1 \wedge \Be _2
\end{equation}

divide out.

Similarly, for three, or N variables, the same ideas hold

\begin{equation}\label{eqn:gaWikiCramers:140}
\begin{bmatrix}
\Ba & \Bb & \Bc
\end{bmatrix}
\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}
= \Bd
\end{equation}

\begin{equation}\label{eqn:gaWikiCramers:160}
\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}
= \frac{1}{\Ba \wedge \Bb \wedge \Bc}
\begin{bmatrix}
\Bd \wedge \Bb \wedge \Bc \\
\Ba \wedge \Bd \wedge \Bc \\
\Ba \wedge \Bb \wedge \Bd
\end{bmatrix}
\end{equation}

Again, for the three variable three equation case this is Cramer's rule since the \(\Be _1 \wedge \Be _2 \wedge \Be _3\) factors of all the wedge products divide out, leaving the familiar determinants.

\subsection{A numeric example}

When there are more equations than variables case, if the equations have a solution, each of the k-vector quotients will be scalars

To illustrate here is the solution of a simple example with three equations and two unknowns.

\begin{equation}\label{eqn:gaWikiCramers:180}
\begin{bmatrix}
1 \\ 1 \\ 0
\end{bmatrix}
x
+
\begin{bmatrix}
1 \\ 1 \\ 1
\end{bmatrix}
y
=
\begin{bmatrix}
1 \\ 1 \\ 2
\end{bmatrix}
\end{equation}

The right wedge product with \((1, 1, 1)\) solves for \(x\)

\begin{equation}\label{eqn:gaWikiCramers:200}
\begin{bmatrix}
1 \\ 1 \\ 0
\end{bmatrix}
\wedge
\begin{bmatrix}
1 \\ 1 \\ 1
\end{bmatrix}
x
=
\begin{bmatrix}
1 \\ 1 \\ 2
\end{bmatrix}
\wedge
\begin{bmatrix}
1 \\ 1 \\ 1
\end{bmatrix}
\end{equation}

and a left wedge product with \((1, 1, 0)\) solves for \(y\)

\begin{equation}\label{eqn:gaWikiCramers:220}
\begin{bmatrix}
1 \\ 1 \\ 0
\end{bmatrix}
\wedge
\begin{bmatrix}
1 \\ 1 \\ 1
\end{bmatrix}
y
=
\begin{bmatrix}
1 \\ 1 \\ 0
\end{bmatrix}
\wedge
\begin{bmatrix}
1 \\ 1 \\ 2
\end{bmatrix}
\end{equation}

Observe that both of these equations have the same factor, so
one can compute this only once (if this was zero it would
indicate the system of equations has no solution).

Collection of results for
\(x\) and \(y\) yields a Cramer's rule like form
(writing \(\Be _i \wedge \Be _j = \Be _{ij}\)):

\begin{equation}\label{eqn:gaWikiCramers:240}
\begin{bmatrix}
x \\ y\end
{bmatrix}
=
\frac{1}{(1, 1, 0) \wedge (1, 1, 1)}
\begin{bmatrix}
(1, 1, 2) \wedge (1, 1, 1) \\
(1, 1, 0) \wedge (1, 1, 2)
\end{bmatrix}
=
\frac{1}{\Be_{13} + \Be_{23}}
\begin{bmatrix}
{-\Be_{13} - \Be_{23}} \\
{2\Be_{13} +2\Be_{23}} \\
\end{bmatrix}
=
\begin{bmatrix}
-1 \\ 2
\end{bmatrix}
\end{equation}

