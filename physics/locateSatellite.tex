%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

%
%
\chapter{Satellite triangulation over sphere}
\index{triangulation}
\label{chap:locateSatellite}
%\date{April 13, 2008.  locateSatellite.tex}

\section{Motivation and preparation}

Was playing around with what is probably traditionally a spherical trig type problem using geometric algebra (locate satellite position using angle measurements from two well separated points).  Origin of the problem was just me looking at my Feynman Lectures introduction where there is a diagram illustrating how triangulation could be used to locate "Sputnik" and thought I had try such a calculation, but in a way that I thought was more realistic.

\imageFigure{../../figures/gabook/satellite}{Satellite location by measuring direction from two points}{fig:satellite}{0.4}

\Cref{fig:satellite} illustrates the problem I attempted to solve.  Pick two arbitrary points \(P_1\), and \(P_2\) on the globe, separated far enough that the curvature of the earth may be a factor.
For this problem it is assumed that the angles to the satellite will be measured concurrently.

Place a fixed reference frame at the center of the earth.  In the figure this is shown translated to the \((0,0)\) point (equator and prime meridian intersection).  I have picked \(\Be_1\) facing east, \(\Be_2\) facing north, and \(\Be_3\) facing outwards from the core.

Each point \(P_i\) can be located by a rotation along the equatorial plane by angle \(\lambda_i\) (measured with an east facing orientation (direction of \(\Be_1\)), and a rotation \(\psi_i\) towards the north (directed towards \(\Be_2\)).

To identify a point on the surface we translate our \((0,0)\) reference frame to that point using the
following rotor equation:

\begin{equation}\label{eqn:locSat:northrotor}
R_{\psi} = \exp(-\Be_{32}\psi/2) = \cos(\psi/2) - \Be_{32}\sin(\psi/2)
\end{equation}
\begin{equation}\label{eqn:locSat:eastrotor}
R_{\lambda} = \exp(-\Be_{31}\lambda/2) = \cos(\lambda/2) - \Be_{31}\sin(\lambda/2)
\end{equation}
\begin{equation}
R(x) = R_{\psi} R_{\lambda} x R_{\lambda}^\dagger R_{\psi}^\dagger
\end{equation}

To verify that I got the sign of these rotations right, I applied them to the unit vectors using a \(\pi/2\) rotation.  We want the following for the equatorial plane rotation:

\begin{equation*}
R_{\lambda}(\pi/2)
\begin{bmatrix}
\Be_1 \\
\Be_2 \\
\Be_3 \\
\end{bmatrix}
R_{\lambda}(\pi/2)^\dagger
=
\begin{bmatrix}
-\Be_3 \\
\Be_2 \\
\Be_1 \\
\end{bmatrix}
\end{equation*}

And for the northwards rotation:

\begin{equation*}
R_{\psi}(\pi/2)
\begin{bmatrix}
\Be_1 \\
\Be_2 \\
\Be_3 \\
\end{bmatrix}
R_{\psi}(\pi/2)^\dagger
=
\begin{bmatrix}
\Be_1 \\
\Be_2 \\
-\Be_3 \\
\end{bmatrix}
\end{equation*}

Verifying this is simple enough using the explicit sine and cosine expansion of the rotors in \eqnref{eqn:locSat:northrotor} and \eqnref{eqn:locSat:eastrotor}.

Once we have the ability to translate our reference frame to each point on the Earth, we can use the inverse rotation to translate our measured unit vector
to the satellite at that point back to the reference frame.

Suppose one calculates a local unit vector \(\alpha'\) towards the satellite by measuring direction cosines in our local reference frame (ie: angle from gravity opposing (up facing) direction, east, and north directions at that point).
Once that is done, that unit vector \(\alpha\) in our reference frame is obtained by inverse rotation:

\begin{equation}
\alpha = R_{\lambda_i}^\dagger R_{\psi_i}^\dagger \alpha' R_{\psi_i} R_{\lambda_i}
\end{equation}

The other place we need this rotation for is to calculate the points \(P_i\) in our reference from (treating this now as being at the core of the earth).  This is just:

\begin{equation}
P_i = R_{\psi} R_{\lambda} A_i \Be_3 R_{\lambda}^\dagger R_{\psi}^\dagger
\end{equation}

Where \(A_i\) is the altitude (relative to the center of the earth) at the point of interest.

\section{Solution}

Solving for the position of the satellite \(P_s\) we have:

\begin{equation}\label{eqn:locateSatellite:20}
P_s = a_1 \alpha_1 + P_1 = a_2 \alpha_2 + P_2
\end{equation}

Solution of this follows directly by taking wedge products.  Solve for \(a_1\) for example, we wedge with \(\alpha_2\) :

\begin{equation}\label{eqn:locateSatellite:40}
a_1 \alpha_1 \wedge \alpha_2 + P_1 \wedge \alpha_2 = a_2 \mathLabelBox{\alpha_2 \wedge \alpha_2}{\(=0\)} + P_2 \wedge \alpha_2
\end{equation}

Provided the points are far enough apart to get distinct \(\alpha_i\) measurements, then we have:
\begin{equation}\label{eqn:locateSatellite:60}
a_1 = \frac{(P_2-P_1) \wedge \alpha_2}{ \alpha_1 \wedge \alpha_2 }.
\end{equation}

Thus the position vector from the core of earth reference frame to the satellite is:

\begin{equation}
P_s = \left(\frac{(P_2-P_1) \wedge \alpha_2}{ \alpha_1 \wedge \alpha_2 }\right) \alpha_1 + P_1
\end{equation}

Notice how all the trigonometry is encoded directly in the rotor equations.  If one had to calculate all this using the spherical trigonometry generalized triangle relations I expect that you would have an ungodly mess of sine and cosines here.

This demonstrates two very distinct applications of the wedge product.  The first was to define an oriented plane, and was used as a generator of rotations (very much like the unit imaginary).  This second application, to solve linear equations takes advantage of \(a \wedge a = 0\) property of the wedge product.  It was convenient as it allowed simple simultaneous solution of the three equations (one for each component) and two unknowns problem in this particular case.

\section{matrix formulation}

Instead of solving with the wedge product one could formulate this as a matrix equation:

\begin{equation}\label{eqn:locSat:twopointsmatrix}
\begin{bmatrix}
\alpha_1 & -\alpha_2 \\
\end{bmatrix}
\begin{bmatrix}
a_1 \\
a_2 \\
\end{bmatrix}
=
\begin{bmatrix}
P_2 - P_1 \\
\end{bmatrix}
\end{equation}

This highlights the fact that the equations are over-specified, which is more obvious still when this is written out in component form:

\begin{equation}
\begin{bmatrix}
\alpha_{11} & -\alpha_{21} \\
\alpha_{12} & -\alpha_{22} \\
\alpha_{13} & -\alpha_{23} \\
\end{bmatrix}
\begin{bmatrix}
a_1 \\
a_2 \\
\end{bmatrix}
=
\begin{bmatrix}
P_{21} - P_{11} \\
P_{22} - P_{12} \\
P_{23} - P_{13} \\
\end{bmatrix}
\end{equation}

We have one more equation than we need to actually solve it, and cannot use matrix inversion directly (Gaussian elimination or a generalized inverse is required).

Recall the figure in the Feynman lectures when the observation points and the satellite are all in the same plane.  For that all that was needed was two angles, whereas we have measured six for each of the direction cosines used above, so the fact that our equations can include more info than required to solve the problem is not unexpected.

We could also generalize this, perhaps to remove measurement error, by utilizing more than two observation points.  This will compound the over-specification of the equations, and makes it clear that we likely want a least squares approach to solve it.
Here is an example of the matrix to solve for three points:

\begin{equation}\label{eqn:locSat:threepointsmatrix}
\begin{bmatrix}
\alpha_1 & -\alpha_2 & 0 \\
-\alpha_1 & 0 & \alpha_3 \\
0 & \alpha_2 & -\alpha_3 \\
\end{bmatrix}
\begin{bmatrix}
a_1 \\
a_2 \\
a_3 \\
\end{bmatrix}
=
\begin{bmatrix}
P_2 - P_1 \\
P_1 - P_3 \\
P_3 - P_2 \\
\end{bmatrix}
\end{equation}

Since the \(\alpha_i\) are vectors, this matrix of rotated direction cosines has dimensions 9 by 3 (just as \eqnref{eqn:locSat:twopointsmatrix} is a 3 by 2 matrix).

\section{Question.  Order of latitude and longitude rotors?}

Looking at a globe, it initially seemed clear to me that these "perpendicular" (abusing the word) rotations could be applied in either order, but their rotors definitely do not commute, so I assume that together the non-commutative bits of the rotors "cancel out".

Question, is it actually true that the end effect of applying these rotors in either order is the same?

\begin{equation}\label{eqn:locateSatellite:80}
x' = R_{\psi} R_{\lambda} x R_{\lambda}^\dagger R_{\psi}^\dagger = R_{\lambda} R_{\psi} x R_{\psi}^\dagger R_{\lambda}^\dagger
\end{equation}

Attempting to show this is true or false by direct brute force expansion is not productive (perhaps would be okay with a symbolic GA calculator).  However, such a direct expansion
of just the rotor products in either order allows for a comparison:

\begin{equation}\label{eqn:locateSatellite:140}
\begin{aligned}
R_{\psi} R_{\lambda}
&= ( \cos(\psi/2) - \Be_{32}\sin(\psi/2) )(\cos(\lambda/2) - \Be_{31}\sin(\lambda/2)) \\
&= \cos(\psi/2)\cos(\lambda/2) - \Be_{32}\sin(\psi/2)\cos(\lambda/2) - \Be_{31} \cos(\psi/2) \sin(\lambda/2) - \Be_{21} \sin(\psi/2) \sin(\lambda/2) \\
\end{aligned}
\end{equation}
\begin{equation}\label{eqn:locateSatellite:160}
\begin{aligned}
R_{\lambda} R_{\psi}
&= (\cos(\lambda/2) - \Be_{31}\sin(\lambda/2)) ( \cos(\psi/2) - \Be_{32}\sin(\psi/2) ) \\
&= \mathLabelBox{\cos(\psi/2)\cos(\lambda/2)}{\(a_0\)} \\
&\qquad + \mathLabelBox{-\Be_{32}\sin(\psi/2)\cos(\lambda/2) - \Be_{31} \cos(\psi/2) \sin(\lambda/2)}{\(A\)} \\
&\qquad + \mathLabelBox{\Be_{21} \sin(\psi/2) \sin(\lambda/2)}{\(B\)}
\end{aligned}
\end{equation}

Observe that these are identical except for an inversion of sign of the \(\Be_{21}\) term.  Using the shorthand above the respective rotations are:

\begin{equation}\label{eqn:locateSatellite:100}
R_{\lambda,\psi}(x) = R_{\psi} R_{\lambda} x R_{\lambda}^\dagger R_{\psi}^\dagger = (a_0 + A - B) x (a_0 -A +B)
\end{equation}

And
\begin{equation}\label{eqn:locateSatellite:120}
R_{\psi,\lambda}(x) = R_{\lambda} R_{\psi} x R_{\psi}^\dagger R_{\lambda}^\dagger = (a_0 + A + B) x (a_0 -A -B)
\end{equation}

And this can be used to disprove the general rotation commutativity.  We take the difference between these two rotation results, and see if it can be shown to equal zero.
Taking differences, also temporarily writing \(a = a_0 + A\), and exploiting a grade one filter since the final result must be a vector we have:

\begin{equation}\label{eqn:locateSatellite:180}
\begin{aligned}
R_{\lambda,\psi}(x) - R_{\psi,\lambda}(x)
&= \gpgradeone{R_{\lambda,\psi}(x) - R_{\psi,\lambda}(x)} \\
&= \gpgradeone{ (a - B) x (a^\dagger +B) -(a + B) x (a^\dagger -B) } \\
&= \gpgradeone{ ( a x a^\dagger -B x B -B x a^\dagger +a x B ) + ( - a x a^\dagger +B x B +a x B -B x a^\dagger ) } \\
&= \gpgradeone{ ( -B x a^\dagger +a x B ) + ( +a x B -B x a^\dagger ) } \\
&= 2\gpgradeone{ -B x a^\dagger +a x B } \\
&= 2\gpgradeone{ -B x (a_0 - A) + (a_0 + A) x B } \\
&= 2 a_0 ( -B x + x B ) + 2 \gpgradeone{ B x A + A x B } \\
&= 4 a_0 x \cdot B + 2 \gpgradeone{ B x A + A x B } \\
&= 4 a_0 x \cdot B + 2 \gpgradeone{ B \cdot x A - A B \cdot x } + 2 \gpgradeone{ B \wedge x A + A x \wedge B }  \\
&= 4 a_0 x \cdot B + 4 (B \cdot x) \cdot A + 2 (B \wedge x) \cdot A + 2 A \cdot (B \wedge x )  \\
&= 4 a_0 x \cdot B + 4 (B \cdot x) \cdot A + 2 (B \wedge x) \cdot A - 2 (B \wedge x ) \cdot A \\
&= 4 a_0 x \cdot B + 4 (B \cdot x) \cdot A \\
&= 4 (B \cdot x) \cdot (-a_0 + A) \\
&= -4 (B \cdot x) \cdot a^\dagger \\
\end{aligned}
\end{equation}

Evaluate this for \(x = \Be_1\) we do not have zero (a vector with \(\Be_2\) and \(\Be_3\) components), and for \(x = \Be_2\) this difference has \(\Be_1\), and \(\Be_3\) components.  However, for \(x = \Be_3\) this is zero.  Thus these
rotations only commute when applied to a vector that is completely normal to the sphere.  This is what messes up the intuition.  Rotating a point (represented by a vector) in either order works fine, but rotating a frame located at the surface back to a different point on the surface, and maintaining the east and north orientations we have to be careful which orientation to use.

So which order is right?  It has to be rotate first in the equatorial plane (\(\lambda)\), then the northwards rotation, where both are great circle rotations.

A numeric confirmation of this is likely prudent.
